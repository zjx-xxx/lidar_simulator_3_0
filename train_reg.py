# =========================================================
# train_reg.py
# é€‚é…æ–°ç‰ˆ RegressionNetworkï¼ˆConv1d + FiLM + é—¨æ§ï¼‰ï¼Œå•è¾“å‡ºè§’åº¦ï¼ˆåº¦ï¼‰
# æŸå¤±ï¼šç¯å½¢è¯¯å·® + Huberï¼ˆSmooth L1ï¼‰
# è¯„ä¼°ï¼šMAE/Hit@3Â° ä½¿ç”¨ç¯å½¢è¯¯å·®
# ä½¿ç”¨æ–¹å¼ï¼šä¸åŸè„šæœ¬åŸºæœ¬ä¸€è‡´
# =========================================================

import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm

from model_reg import RegressionNetwork  # ä½ æä¾›çš„æ–°ç‰ˆ

# =========================
# è®¾å¤‡ä¸éšæœºç§å­
# =========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def set_seed(seed=42):
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


set_seed(2025)


# =========================
# ç¯å½¢è¾…åŠ©
# =========================
def ang_wrap_deg(delta):
    # æŠŠä»»æ„è§’åº¦å·®æ˜ å°„åˆ° [-180, 180)
    return (delta + 180.0) % 360.0 - 180.0


# =========================
# Huberï¼ˆSmooth L1ï¼‰
# =========================
def huber_loss(x, delta=5.0):
    # x çš„å•ä½æ˜¯â€œåº¦â€ï¼Œdelta æ¨è 3~10Â°
    absx = torch.abs(x)
    quad = 0.5 * x ** 2
    lin = delta * (absx - 0.5 * delta)
    return torch.where(absx <= delta, quad, lin)


# =========================
# ç¯å½¢ + Huberï¼ˆå¸¦æ ·æœ¬æƒé‡ï¼Œä¸åŸæƒé‡ç­–ç•¥å…¼å®¹ï¼‰
# =========================
def wrapped_huber_angle_loss(pred_deg, target_deg, base_weight=1.0, angle_weight=10.0, delta=5.0):
    """
    pred_deg: [B] æˆ– [B,1] é¢„æµ‹è§’åº¦ï¼ˆåº¦ï¼‰
    target_deg: [B] æˆ– [B,1] ç›®æ ‡è§’åº¦ï¼ˆåº¦ï¼‰
    """
    if pred_deg.ndim > 1:
        pred_deg = pred_deg.view(-1)
    if target_deg.ndim > 1:
        target_deg = target_deg.view(-1)

    # ç¯å½¢è¯¯å·®
    ang_err = ang_wrap_deg(pred_deg - target_deg)

    # æ ·æœ¬æƒé‡ï¼šæ²¿ç”¨ä½ åŸç­–ç•¥ï¼ˆæŒ‰ |Î¸| åŠ æƒï¼‰
    w = base_weight + angle_weight * torch.abs(target_deg) / 30.0

    loss = w * huber_loss(ang_err, delta=delta)
    return loss.mean()


# =========================
# Datasetï¼ˆå…¼å®¹ç¦»æ•£ embedding ä¸è¿ç»­ç‰¹å¾ä¸¤ç§è·¯å¾„ï¼‰
# =========================
class LidarRegressionDataset(Dataset):
    def __init__(self, X_main, road_type, turn_direction, y, use_embedding=True):
        self.X_main = torch.tensor(X_main, dtype=torch.float32)
        self.use_embedding = use_embedding

        if use_embedding:
            # ä½œä¸ºç±»åˆ« idï¼ˆæ•´æ•°ï¼‰
            self.road_type = torch.tensor(road_type, dtype=torch.long).view(-1)
            self.turn_direction = torch.tensor(turn_direction, dtype=torch.long).view(-1)
        else:
            # ä½œä¸ºè¿ç»­ç‰¹å¾ï¼ˆæµ®ç‚¹ï¼‰
            self.road_type = torch.tensor(road_type, dtype=torch.float32).view(-1)
            self.turn_direction = torch.tensor(turn_direction, dtype=torch.float32).view(-1)

        self.y = torch.tensor(y, dtype=torch.float32).view(-1)

    def __len__(self):
        return len(self.X_main)

    def __getitem__(self, idx):
        return (
            self.X_main[idx],
            self.road_type[idx],
            self.turn_direction[idx],
            self.y[idx],
        )


# =========================
# è¯„ä¼°å‡½æ•°ï¼ˆç¯å½¢ MAE / Hit@3Â°ï¼‰
# =========================
@torch.no_grad()
def evaluate(model, dataloader, base_weight=1.0, angle_weight=10.0,
             hit_threshold_deg=3.0, delta=5.0):
    model.eval()
    total_loss, total_mae, total_hit, total_samples = 0.0, 0.0, 0.0, 0

    for x_lidar, road_type, turn_direction, target in dataloader:
        x_lidar = x_lidar.to(device)
        road_type = road_type.to(device)
        turn_direction = turn_direction.to(device)
        target = target.to(device)

        outputs = model(x_lidar, road_type, turn_direction)  # [B]ï¼ˆä½ çš„æ¨¡å‹é‡Œ squeeze æ‰äº†ï¼‰
        loss = wrapped_huber_angle_loss(outputs, target,
                                        base_weight=base_weight,
                                        angle_weight=angle_weight,
                                        delta=delta)

        # ç¯å½¢è¯¯å·® -> MAE / Hit
        if target.ndim > 1:
            target_flat = target.view(-1)
        else:
            target_flat = target
        err = torch.abs(ang_wrap_deg(outputs - target_flat))
        mae = torch.sum(err).item()
        hit = torch.sum((err < hit_threshold_deg).float()).item()

        bs = target_flat.size(0)
        total_loss += loss.item() * bs
        total_mae += mae
        total_hit += hit
        total_samples += bs

    avg_loss = total_loss / total_samples
    avg_mae = total_mae / total_samples
    hit_rate = total_hit / total_samples
    return avg_loss, avg_mae, hit_rate


# =========================
# è®­ç»ƒä¸»å¾ªç¯ï¼ˆæ¥å£ä¿æŒä¸å˜ï¼‰
# =========================
def train(model, train_data, val_data,
          num_epochs=1000, batch_size=64, learning_rate=1e-3,
          early_stop_patience=50,
          base_weight=1.0, angle_weight=10.0, delta=5.0):
    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)

    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=10
    )

    history = {"train_loss": [], "val_loss": [], "val_mae": [], "val_hit3": [], "lr": []}

    best_val_loss = float('inf')
    best_state = None
    patience = 0

    for epoch in tqdm(range(1, num_epochs + 1), desc="Training Progress"):
        model.train()
        running_loss, seen = 0.0, 0

        for x_lidar, road_type, turn_direction, target in train_loader:
            x_lidar = x_lidar.to(device)
            road_type = road_type.to(device)
            turn_direction = turn_direction.to(device)
            target = target.to(device)

            optimizer.zero_grad()
            outputs = model(x_lidar, road_type, turn_direction)  # [B]
            loss = wrapped_huber_angle_loss(outputs, target,
                                            base_weight=base_weight,
                                            angle_weight=angle_weight,
                                            delta=delta)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

            bs = x_lidar.size(0)
            running_loss += loss.item() * bs
            seen += bs

        train_loss = running_loss / max(seen, 1)

        # éªŒè¯
        val_loss, val_mae, val_hit3 = evaluate(
            model, val_loader,
            base_weight=base_weight, angle_weight=angle_weight,
            hit_threshold_deg=3.0, delta=delta
        )

        scheduler.step(val_loss)

        # è®°å½•
        history["train_loss"].append(train_loss)
        history["val_loss"].append(val_loss)
        history["val_mae"].append(val_mae)
        history["val_hit3"].append(val_hit3)
        history["lr"].append(optimizer.param_groups[0]['lr'])

        print(f"Epoch {epoch} | Train Loss: {train_loss:.4f} | "
              f"Val Loss: {val_loss:.4f} | Val MAE(deg): {val_mae:.3f} | "
              f"Hit@3Â°: {val_hit3 * 100:.1f}% | LR: {optimizer.param_groups[0]['lr']:.2e}")

        # Early Stopping
        if val_loss < best_val_loss - 1e-4:
            best_val_loss = val_loss
            best_state = model.state_dict()
            patience = 0
            os.makedirs('./model', exist_ok=True)
            torch.save(best_state, './model/model_regression_best.pth')
            print(f"âœ… Best model updated and saved at epoch {epoch}")
        else:
            patience += 1
            if patience >= early_stop_patience:
                print(f"â¹ Early stopping at epoch {epoch} "
                      f"(no improvement for {early_stop_patience} epochs)")
                break

    # æ¢å¤æœ€ä½³æ¨¡å‹
    if best_state is not None:
        model.load_state_dict(best_state)
    os.makedirs('./model', exist_ok=True)
    torch.save(model.state_dict(), './model/model_regression_last.pth')
    print("ğŸ¯ Final model saved.")
    return history


# =========================
# ç”»è®­ç»ƒæ›²çº¿ï¼ˆæ²¿ç”¨ï¼‰
# =========================
def plot_history(history, out_path='./model/training_curves.png'):
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    epochs = np.arange(1, len(history["train_loss"]) + 1)

    # Loss
    plt.figure()
    plt.plot(epochs, history["train_loss"], label='Train Loss')
    plt.plot(epochs, history["val_loss"], label='Val Loss')
    plt.xlabel('Epoch');
    plt.ylabel('Loss');
    plt.title('Loss vs. Epoch')
    plt.legend();
    plt.grid(True);
    plt.tight_layout()
    plt.savefig(out_path.replace('.png', '_loss.png'));
    plt.close()

    # MAE
    plt.figure()
    plt.plot(epochs, history["val_mae"], label='Val MAE (deg)')
    plt.xlabel('Epoch');
    plt.ylabel('MAE (deg)');
    plt.title('Validation MAE vs. Epoch')
    plt.legend();
    plt.grid(True);
    plt.tight_layout()
    plt.savefig(out_path.replace('.png', '_mae.png'));
    plt.close()

    # Hit@3Â°
    plt.figure()
    plt.plot(epochs, history["val_hit3"], label='Hit@3Â°')
    plt.xlabel('Epoch');
    plt.ylabel('Hit Rate');
    plt.title('Hit@3Â° vs. Epoch')
    plt.legend();
    plt.grid(True);
    plt.tight_layout()
    plt.savefig(out_path.replace('.png', '_hit3.png'));
    plt.close()

    # Learning Rate
    plt.figure()
    plt.plot(epochs, history["lr"], label='Learning Rate')
    plt.xlabel('Epoch');
    plt.ylabel('LR');
    plt.title('Learning Rate vs. Epoch')
    plt.legend();
    plt.grid(True);
    plt.tight_layout()
    plt.savefig(out_path.replace('.png', '_lr.png'));
    plt.close()


# =========================
# æ•°æ®è¯»å–å‡½æ•°ï¼ˆä¿æŒä¸åŸç‰ˆå…¼å®¹ï¼‰
# =========================
def load_split(prefix):
    """
    è¿”å›ï¼š
      X_main: [N, L]ï¼ŒL é»˜è®¤ 360
      road_type: [N,1]  (ç±»åˆ« id æˆ– è¿ç»­å€¼)
      turn_direction: [N,1] (ç±»åˆ« id æˆ– è¿ç»­å€¼)
      y: [N,1] (è§’åº¦ï¼Œå•ä½åº¦)
    """
    X_main = pd.read_csv(f'./mydata/X_{prefix}.csv', header=None).values.astype(np.float32)
    road_type = pd.read_csv(f'./mydata/type/Y_{prefix}.csv', header=None).values
    turn_direction = pd.read_csv(f'./mydata/towards/Y_{prefix}.csv', header=None).values
    y = pd.read_csv(f'./mydata/direction/Y_{prefix}.csv', header=None).values.astype(np.float32)

    if road_type.ndim == 1: road_type = road_type.reshape(-1, 1)
    if turn_direction.ndim == 1: turn_direction = turn_direction.reshape(-1, 1)
    if y.ndim == 1: y = y.reshape(-1, 1)

    # ç»Ÿä¸€æ ‡ç­¾åˆ° [-180,180)
    y = ((y + 180.0) % 360.0) - 180.0
    return X_main, road_type, turn_direction, y


def _extract_y(sample):
    """
    ä»æ ·æœ¬ä¸­é²æ£’æå– yï¼š
    - tuple/list: å–æœ€åä¸€ä¸ª
    - dict: å– 'y' é”®æˆ–æœ€åä¸€ä¸ªå€¼
    è¿”å› torch.Tensor (1,) æˆ–æ ‡é‡å¼ é‡
    """
    if isinstance(sample, dict):
        if 'y' in sample:
            y = sample['y']
        else:
            # å–æœ€åä¸€ä¸ªé”®çš„å€¼
            # æ³¨æ„ï¼šPython 3.7+ å­—å…¸æœ‰æ’å…¥åº
            y = list(sample.values())[-1]
    elif isinstance(sample, (tuple, list)):
        y = sample[-1]
    else:
        raise TypeError(f"Unsupported sample type for extracting y: {type(sample)}")

    if isinstance(y, torch.Tensor):
        return y.detach().float().reshape(-1)
    else:
        # å¯èƒ½æ˜¯ numpy / æ ‡é‡
        return torch.as_tensor(y, dtype=torch.float32).reshape(-1)


def collect_y_tensor(dataset, batch_size=4096, num_workers=0):
    """
    é«˜æ•ˆæ”¶é›†æ•´ä¸ª dataset çš„ y åˆ°ä¸€ä¸ª 1D Tensorã€‚
    ä¸ç”¨é€æ¡ __getitem__ï¼Œè€Œæ˜¯ç”¨ DataLoader æ‰¹å¤„ç†ã€‚
    æ³¨æ„ï¼šcollate_fn é»˜è®¤å³å¯ï¼›æˆ‘ä»¬åªä» batch ä¸­æŠ½ yã€‚
    """
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,
                        num_workers=num_workers, pin_memory=False)
    ys = []
    for batch in loader:
        # batch å¯èƒ½æ˜¯ tuple/list/dictï¼Œä¸å•æ¡ä¸€è‡´
        ys.append(_extract_y(batch))
    return torch.cat(ys, dim=0)


def describe_tensor_1d(name, ys: torch.Tensor, bins=10):
    ys = ys[torch.isfinite(ys)]
    if ys.numel() == 0:
        print(f"\n--- {name} Dataset Statistics ---")
        print("Empty or non-finite labels.")
        return
    q = torch.tensor([0.25, 0.5, 0.75], dtype=torch.float32, device=ys.device)
    qv = torch.quantile(ys, q).cpu().tolist()
    h = torch.histc(ys, bins=bins, min=ys.min(), max=ys.max()).cpu().tolist()
    print(f"\n--- {name} Dataset Statistics ---")
    print(f"Count: {ys.numel()}")
    print(f"Min:   {ys.min().item():.6f}")
    print(f"Max:   {ys.max().item():.6f}")
    print(f"Mean:  {ys.mean().item():.6f}")
    # unbiased=False -> ä¸ numpy.std(ddof=0) ä¸€è‡´
    print(f"Std:   {ys.std(unbiased=False).item():.6f}")
    print(f"25/50/75% quantiles: [{qv[0]:.6f}, {qv[1]:.6f}, {qv[2]:.6f}]")
    print(f"Histogram ({bins} bins): {h}")


def describe_dataset(name, dataset, bins=10, batch_size=4096, num_workers=0):
    ys = collect_y_tensor(dataset, batch_size=batch_size, num_workers=num_workers)
    describe_tensor_1d(name, ys, bins=bins)


# =========================
# ä¸»å…¥å£ï¼ˆä¸åŸç‰ˆç›¸åŒé£æ ¼ï¼‰
# =========================
if __name__ == '__main__':
    X_train, road_train, turn_train, y_train = load_split('train')
    X_val, road_val, turn_val, y_val = load_split('test')

    print('Train shapes:', X_train.shape, road_train.shape, turn_train.shape, y_train.shape)
    print('Val   shapes:', X_val.shape, road_val.shape, turn_val.shape, y_val.shape)

    # å¦‚æœ road/turn æ˜¯ç¦»æ•£ç±»åˆ« id -> è®¾ Trueï¼›è‹¥ä¸ºè¿ç»­ç‰¹å¾ -> è®¾ False
    USE_EMB = True

    train_dataset = LidarRegressionDataset(X_train, road_train, turn_train, y_train, use_embedding=USE_EMB)
    val_dataset = LidarRegressionDataset(X_val, road_val, turn_val, y_val, use_embedding=USE_EMB)

    print(f"Train shapes: {X_train.shape} {y_train.shape} ...")  # ä½ å·²æœ‰
    print(f"Val   shapes: {X_val.shape} {y_val.shape} ...")

    # ç»Ÿè®¡ yï¼ˆè‡ªåŠ¨é€‚é… (x, y) / (x, a, b, y) / dictï¼‰
    describe_dataset("Train", train_dataset, bins=10, batch_size=4096, num_workers=0)
    describe_dataset("Val", val_dataset, bins=10, batch_size=4096, num_workers=0)

    # ä¸ä½  model_reg.py çš„é»˜è®¤å‚æ•°ä¿æŒä¸€è‡´ï¼ˆn_road / n_turn è¯·æŒ‰ä½ çš„çœŸå®ç±»åˆ«æ•°æ”¹ï¼‰
    model = RegressionNetwork(
        use_embedding=USE_EMB,
        n_road=10,  # â˜… æŒ‰å®é™…ç±»åˆ«æ•°è°ƒæ•´
        n_turn=5,  # â˜… æŒ‰å®é™…ç±»åˆ«æ•°è°ƒæ•´
        # å…¶ä½™è¶…å‚ä¿æŒé»˜è®¤å³å¯
    ).to(device)

    history = train(model, train_dataset, val_dataset,
                    num_epochs=1000,
                    batch_size=64,
                    learning_rate=1e-3,
                    early_stop_patience=100,
                    base_weight=1.0,
                    angle_weight=10.0,
                    delta=5.0)

    plot_history(history, out_path='./model/training_curves.png')
    print('ğŸ“ˆ Curves saved to ./model/training_curves_*')

    # # å¯é€‰ï¼šæ¨ç†ç¤ºä¾‹
    # with torch.no_grad():
    #     x_lidar, road, turn, gt = val_dataset[0]
    #     pred_deg = model(x_lidar.unsqueeze(0).to(device),
    #                      road.unsqueeze(0).to(device),
    #                      turn.unsqueeze(0).to(device))
    #     pred_deg = RegressionNetwork.vec2angle_deg(pred_deg)  # è§„èŒƒåˆ° [-180,180)
    #     print("Pred angle (deg):", float(pred_deg.cpu()))
